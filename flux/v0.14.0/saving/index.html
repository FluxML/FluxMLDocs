<!DOCTYPE html><HTML lang="en"><head><script charset="utf-8" src="../../../assets/default/multidoc_injector.js" type="text/javascript"></script><script charset="utf-8" type="text/javascript">window.MULTIDOCUMENTER_ROOT_PATH = '/'</script><script charset="utf-8" src="../../../assets/default/flexsearch.bundle.js" type="text/javascript"></script><script charset="utf-8" src="../../../assets/default/flexsearch_integration.js" type="text/javascript"></script><meta charset="UTF-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>Saving &amp; Loading · Flux</title><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-36890222-9"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-36890222-9', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner="" src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script data-main="../assets/documenter.js" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" data-theme-name="documenter-dark" data-theme-primary-dark="" href="../assets/themes/documenter-dark.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="documenter-light" data-theme-primary="" href="../assets/themes/documenter-light.css" rel="stylesheet" type="text/css"/><script src="../assets/themeswap.js"></script><link href="../assets/flux.css" rel="stylesheet" type="text/css"/><link href="nothing/flux/stable/saving/" rel="canonical"/><link href="../../../assets/default/multidoc.css" rel="stylesheet" type="text/css"/><link href="../../../assets/default/flexsearch.css" rel="stylesheet" type="text/css"/></head><body><nav id="multi-page-nav"><div class="hidden-on-mobile" id="nav-items"><a class="nav-link active nav-item" href="../../">Flux</a><div class="nav-dropdown"><button class="nav-item dropdown-label">Building Blocks</button><div class="nav-dropdown-container nav-mega-dropdown-container"><div class="nav-mega-column"><div class="column-header">Neural Network primitives</div><ul class="column-content"><a class="nav-link nav-item" href="../../../nnlib/">NNlib</a><a class="nav-link nav-item" href="../../../functors/">Functors</a></ul></div><div class="nav-mega-column"><div class="column-header">Automatic differentiation libraries</div><ul class="column-content"><a class="nav-link nav-item" href="../../../zygote/">Zygote</a></ul></div><div class="nav-mega-column"><div class="column-header">Neural Network primitives</div><ul class="column-content"><a class="nav-link nav-item" href="../../../nnlib/">NNlib</a></ul></div></div></div><div class="nav-dropdown"><button class="nav-item dropdown-label">Training</button><div class="nav-dropdown-container nav-mega-dropdown-container"><div class="nav-mega-column"><div class="column-header">Data Wrangling</div><ul class="column-content"><a class="nav-link nav-item" href="../../../mlutils/">MLUtils</a><a class="nav-link nav-item" href="../../../onehotarrays/">OneHotArrays</a></ul></div><div class="nav-mega-column"><div class="column-header">Data Augmentation</div><ul class="column-content"><a class="nav-link nav-item" href="../../../dataaugmentation/">DataAugmentation</a></ul></div><div class="nav-mega-column"><div class="column-header">Datasets</div><ul class="column-content"><a class="nav-link nav-item" href="../../../mldatasets/">MLDatasets</a></ul></div><div class="nav-mega-column"><div class="column-header">Schedulers</div><ul class="column-content"><a class="nav-link nav-item" href="../../../paramschedulers/dev/">ParameterSchedulers</a></ul></div></div></div><div class="nav-dropdown"><button class="nav-item dropdown-label">Models</button><div class="nav-dropdown-container nav-mega-dropdown-container"><div class="nav-mega-column"><div class="column-header">Computer Vision</div><ul class="column-content"><a class="nav-link nav-item" href="../../../metalhead/">Metalhead</a></ul></div><div class="nav-mega-column"><div class="column-header">Natural Language Processing</div><ul class="column-content"><a class="nav-link nav-item" href="../../../transformers/">Transformers</a></ul></div></div></div><div class="search nav-item"><input id="search-input" placeholder="Search..."/><ul class="suggestions hidden" id="search-result-container"></ul><div class="search-keybinding">/</div></div></div><button id="multidoc-toggler"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg></button></nav><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img alt="Flux logo" class="docs-light-only" src="../assets/logo.png"/><img alt="Flux logo" class="docs-dark-only" src="../assets/logo-dark.png"/></a><form action="../search/" class="docs-search"><input class="docs-search-query" id="documenter-search-query" name="q" placeholder="Search docs" type="text"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Welcome</a></li><li><span class="tocitem">Guide</span><ul><li><a class="tocitem" href="../models/quickstart/">Quick Start</a></li><li><a class="tocitem" href="../models/overview/">Fitting a Line</a></li><li><a class="tocitem" href="../models/basics/">Gradients and Layers</a></li><li><a class="tocitem" href="../training/training/">Training</a></li><li><a class="tocitem" href="../models/recurrence/">Recurrence</a></li><li><a class="tocitem" href="../gpu/">GPU Support</a></li><li class="is-active"><a class="tocitem" href="">Saving &amp; Loading</a><ul class="internal"><li><a class="tocitem" href="#Checkpointing"><span>Checkpointing</span></a></li><li class="toplevel"><a class="tocitem" href="#Saving-Models-as-Julia-Structs"><span>Saving Models as Julia Structs</span></a></li></ul></li><li><a class="tocitem" href="../performance/">Performance Tips</a></li></ul></li><li><a class="tocitem" href="../ecosystem/">Ecosystem</a></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../models/layers/">Built-in Layers</a></li><li><a class="tocitem" href="../models/activation/">Activation Functions</a></li><li><a class="tocitem" href="../utilities/">Weight Initialisation</a></li><li><a class="tocitem" href="../models/losses/">Loss Functions</a></li><li><a class="tocitem" href="../training/reference/">Training API</a></li><li><a class="tocitem" href="../training/optimisers/">Optimisation Rules</a></li><li><a class="tocitem" href="../outputsize/">Shape Inference</a></li><li><a class="tocitem" href="../destructure/">Flat vs. Nested</a></li><li><a class="tocitem" href="../training/callbacks/">Callback Helpers</a></li><li><a class="tocitem" href="../training/zygote/">Gradients – Zygote.jl</a></li><li><a class="tocitem" href="../data/mlutils/">Batching Data – MLUtils.jl</a></li><li><a class="tocitem" href="../data/onehot/">OneHotArrays.jl</a></li><li><a class="tocitem" href="../models/nnlib/">Low-level Operations – NNlib.jl</a></li><li><a class="tocitem" href="../models/functors/">Nested Structures – Functors.jl</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/linear_regression/">Linear Regression</a></li><li><a class="tocitem" href="../tutorials/logistic_regression/">Logistic Regression</a></li><li><a class="tocitem" href="../models/advanced/">Custom Layers</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Guide</a></li><li class="is-active"><a href="">Saving &amp; Loading</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="">Saving &amp; Loading</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/FluxML/Flux.jl/blob/master/docs/src/saving.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" href="#" id="documenter-settings-button" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" href="#" id="documenter-sidebar-button"></a></div></header><article class="content" id="documenter-page"><h1 id="Saving-and-Loading-Models"><a class="docs-heading-anchor" href="#Saving-and-Loading-Models">Saving and Loading Models</a><a id="Saving-and-Loading-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Saving-and-Loading-Models" title="Permalink"></a></h1><p>You may wish to save models so that they can be loaded and run in a later session. Flux provides a number of ways to do this.  The recommended way, which is the most robust one for long term storage,  is to use <a href="../destructure/#Flux.state"><code>Flux.state</code></a> in combination with a serialization format like <a href="https://juliaio.github.io/JLD2.jl/dev/">JLD2.jl</a> or <a href="https://github.com/JuliaIO/BSON.jl">BSON.jl</a>.</p><p>Save a model:</p><pre><code class="language-julia-repl hljs">julia&gt; using Flux

julia&gt; struct MyModel
           net
       end

julia&gt; Flux.@functor MyModel

julia&gt; MyModel() = MyModel(Chain(Dense(10, 5, relu), Dense(5, 2)));

julia&gt; model = MyModel()
MyModel(Chain(Dense(10 =&gt; 5, relu), Dense(5 =&gt; 2)))

julia&gt; model_state = Flux.state(model);

julia&gt; using JLD2

julia&gt; jldsave("mymodel.jld2"; model_state)</code></pre><p>Load it again in a new session using <a href="../destructure/#Flux.loadmodel!"><code>Flux.loadmodel!</code></a>:</p><pre><code class="language-julia-repl hljs">julia&gt; using Flux, JLD2

julia&gt; model_state = JLD2.load("mymodel.jld2", "model_state");

julia&gt; model = MyModel(); # MyModel definition must be available

julia&gt; Flux.loadmodel!(model, model_state);</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>If a saved model's parameters are stored on the GPU, the model will not load later on if there is no GPU support available. It's best to <a href="../gpu/">move your model to the CPU</a> with <code>cpu(model)</code> before saving it.</p></div></div><h2 id="Checkpointing"><a class="docs-heading-anchor" href="#Checkpointing">Checkpointing</a><a id="Checkpointing-1"></a><a class="docs-heading-anchor-permalink" href="#Checkpointing" title="Permalink"></a></h2><p>In longer training runs it's a good idea to periodically save your model, so that you can resume if training is interrupted (for example, if there's a power cut). </p><pre><code class="language-julia-repl hljs">julia&gt; using Flux: throttle

julia&gt; using JLD2

julia&gt; m = Chain(Dense(10 =&gt; 5, relu), Dense(5 =&gt; 2))
Chain(
  Dense(10 =&gt; 5, relu),                 # 55 parameters
  Dense(5 =&gt; 2),                        # 12 parameters
)                   # Total: 4 arrays, 67 parameters, 524 bytes.

julia&gt; for epoch in 1:10
          # ... train model ...
          jldsave("model-checkpoint.jld2", model_state = Flux.state(m))
       end;</code></pre><p>This will update the <code>"model-checkpoint.jld2"</code> every epoch.</p><p>You can get more advanced by saving a series of models throughout training, for example</p><pre><code class="language-julia hljs">jldsave("model-$(now()).jld2", model_state = Flux.state(m))</code></pre><p>will produce a series of models like <code>"model-2018-03-06T02:57:10.41.jld2"</code>. You could also store the current test set loss, so that it's easy to (for example) revert to an older copy of the model if it starts to overfit.</p><pre><code class="language-julia hljs">jldsave("model-$(now()).jld2", model_state = Flux.state(m), loss = testloss())</code></pre><p>Note that to resume a model's training, you might need to restore other stateful parts of your training loop. Possible examples are the optimiser state and the randomness used to partition the original data into the training and validation sets.</p><p>You can store the optimiser state alongside the model, to resume training exactly where you left off: </p><pre><code class="language-julia hljs">model = MyModel()
opt_state = Flux.setup(AdamW(), model)

# ... train model ...

model_state = Flux.state(model)
jldsave("checkpoint_epoch=42.jld2"; model_state, opt_state)</code></pre><h1 id="Saving-Models-as-Julia-Structs"><a class="docs-heading-anchor" href="#Saving-Models-as-Julia-Structs">Saving Models as Julia Structs</a><a id="Saving-Models-as-Julia-Structs-1"></a><a class="docs-heading-anchor-permalink" href="#Saving-Models-as-Julia-Structs" title="Permalink"></a></h1><p>Models are just normal Julia structs, so it's fine to use any Julia storage format to save the struct as it is instead of saving the state returned by <a href="../destructure/#Flux.state"><code>Flux.state</code></a>.  <a href="https://github.com/JuliaIO/BSON.jl">BSON.jl</a> is particularly convenient for this, since it can also save anynomous functions, which are sometimes part of a model definition.</p><p>Save a model:</p><pre><code class="language-julia-repl hljs">julia&gt; using Flux

julia&gt; model = Chain(Dense(10, 5, NNlib.relu), Dense(5, 2));

julia&gt; using BSON: @save

julia&gt; @save "mymodel.bson" model</code></pre><p>Load it again in a new session:</p><pre><code class="language-julia-repl hljs">julia&gt; using Flux, BSON

julia&gt; BSON.@load "mymodel.bson" model

julia&gt; model
Chain(
  Dense(10 =&gt; 5, relu),                 # 55 parameters
  Dense(5 =&gt; 2),                        # 12 parameters
)                   # Total: 4 arrays, 67 parameters, 524 bytes.</code></pre><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Saving models this way could lead to compatibility issues across julia versions and across Flux versions if some of the Flux layers' internals are changed. It is therefore not recommended for long term storage, use <a href="../destructure/#Flux.state"><code>Flux.state</code></a> instead.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Previous versions of Flux suggested saving only the model weights using <code>@save "mymodel.bson" params(model)</code>. This is no longer recommended and even strongly discouraged. Saving models this way will only store the trainable parameters which will result in incorrect behavior for layers like <code>BatchNorm</code>.</p></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gpu/">« GPU Support</a><a class="docs-footer-nextpage" href="../performance/">Performance Tips »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label></p><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div><p></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Friday 14 July 2023 11:08">Friday 14 July 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></HTML>